# High-Throughput Logs Distributor

A scalable, pull-based work queue system for distributing and processing log messages with automatic load balancing, failure resilience, and autoscaling capabilities.

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                EMITTER POOL                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚Emitter-1 â”‚  â”‚Emitter-2 â”‚  â”‚Emitter-3 â”‚  â”‚Emitter-4 â”‚  â”‚Emitter-5 â”‚     â”‚
â”‚  â”‚  emit()  â”‚  â”‚  emit()  â”‚  â”‚  emit()  â”‚  â”‚  emit()  â”‚  â”‚  emit()  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚             â”‚
        â”‚   HTTP POST /submit (push logs to distributor)       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              DISTRIBUTOR                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  FastAPI Service (Port 8000)                                           â”‚ â”‚
â”‚  â”‚                                                                         â”‚ â”‚
â”‚  â”‚  POST /submit        - Receive logs from emitters                      â”‚ â”‚
â”‚  â”‚  POST /get_work      - Analyzers pull work (returns log if available) â”‚ â”‚
â”‚  â”‚  POST /status        - Receive status updates & heartbeats             â”‚ â”‚
â”‚  â”‚  GET  /stats         - Get system statistics                           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Task Queue    â”‚  â”‚  In-Progress Map â”‚  â”‚  Background Monitor     â”‚   â”‚
â”‚  â”‚   (FIFO deque)  â”‚  â”‚  {task_id: Task} â”‚  â”‚  - Heartbeat timeout    â”‚   â”‚
â”‚  â”‚                 â”‚  â”‚  + heartbeats    â”‚  â”‚  - Task requeuing       â”‚   â”‚
â”‚  â”‚  [Task, Task,   â”‚  â”‚                  â”‚  â”‚  - Runs every 5s        â”‚   â”‚
â”‚  â”‚   Task, ...]    â”‚  â”‚                  â”‚  â”‚                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                                      â”‚
        HTTP POST /get_work (pull)              HTTP POST /status (heartbeat)
                        â”‚                                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             ANALYZER POOL                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Autoscaler (optional)                                              â”‚    â”‚
â”‚  â”‚  - Monitors queue depth                                             â”‚    â”‚
â”‚  â”‚  - Scales up when queue > threshold                                 â”‚    â”‚
â”‚  â”‚  - Scales down when queue < threshold                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                              â”‚
â”‚  Weight-Based Load Balancing (Implicit):                                    â”‚
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Analyzer-1     â”‚  â”‚   Analyzer-2     â”‚  â”‚   Analyzer-3     â”‚          â”‚
â”‚  â”‚   weight: 0.2    â”‚  â”‚   weight: 0.3    â”‚  â”‚   weight: 0.5    â”‚          â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚          â”‚
â”‚  â”‚   max_tasks: 2   â”‚  â”‚   max_tasks: 3   â”‚  â”‚   max_tasks: 5   â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚                  â”‚          â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â” â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â” â”‚          â”‚
â”‚  â”‚  â”‚Task â”‚â”‚Task â”‚  â”‚  â”‚  â”‚Task â”‚â”‚Task â”‚ â”‚  â”‚  â”‚Task â”‚â”‚Task â”‚ â”‚          â”‚
â”‚  â”‚  â”‚  1  â”‚â”‚  2  â”‚  â”‚  â”‚  â”‚  3  â”‚â”‚  4  â”‚ â”‚  â”‚  â”‚  6  â”‚â”‚  7  â”‚ â”‚          â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜ â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜ â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”        â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â” â”‚          â”‚
â”‚  â”‚  (polling slow)  â”‚  â”‚  â”‚Task â”‚        â”‚  â”‚  â”‚Task â”‚â”‚Task â”‚ â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚  â”‚  5  â”‚        â”‚  â”‚  â”‚  8  â”‚â”‚  9  â”‚ â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜        â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜ â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”        â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚  (polling med)   â”‚  â”‚  â”‚Task â”‚        â”‚          â”‚
â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚  â”‚ 10  â”‚        â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”˜        â”‚          â”‚
â”‚                                               â”‚                  â”‚          â”‚
â”‚                                               â”‚  (polling fast)  â”‚          â”‚
â”‚                                               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                              â”‚
â”‚  Result: Analyzer-3 processes ~50% of work, Analyzer-2 ~30%, Analyzer-1 ~20%â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Descriptions

### 1. Emitter

**Purpose**: Generates and sends log messages to the distributor.

**Key Features**:
- Generates realistic log messages with various levels (INFO, WARN, ERROR, etc.)
- Sends logs via HTTP POST to `/submit` endpoint
- Runs independently with configurable emission intervals
- Includes metadata (timestamp, source, request IDs)

**Implementation**: `emitter/log_emitter.py` - `LogEmitter` class

---

### 2. Emitter Pool

**Purpose**: Manages multiple emitters running concurrently.

**Key Features**:
- Creates and manages N emitter instances
- Each emitter runs in its own asyncio task
- Randomized emission intervals for realistic traffic patterns
- Thread-safe statistics tracking (total emitted, per-emitter counts)
- Graceful start/stop of all emitters

**Implementation**: `emitter/log_emitter.py` - `LogEmitterPool` class

**Configuration**:
```python
emitter_pool = LogEmitterPool(
    distributor_url="http://localhost:8000",
    num_emitters=5,           # Number of concurrent emitters
    base_interval=1.0,        # Base emission interval (seconds)
    interval_jitter=0.5       # Random variance (Â±0.5s)
)
```

---

### 3. Analyzer

**Purpose**: Worker that pulls and processes log messages from the distributor.

**Key Features**:
- **Pull-based**: Actively requests work from distributor (no push)
- **Weighted concurrency**: Weight determines max concurrent tasks
- **Heartbeat mechanism**: Sends periodic status updates
- **Graceful failure handling**: Tasks timeout and requeue if analyzer fails
- **Statistics tracking**: Tracks processed count, failures, throughput

**Weight to Concurrency Conversion**:
```python
weight = 0.3
max_concurrent_tasks = max(1, int(weight * 10))  # = 3 tasks

# Examples:
# weight 0.1 â†’ 1 concurrent task
# weight 0.2 â†’ 2 concurrent tasks
# weight 0.3 â†’ 3 concurrent tasks
# weight 0.5 â†’ 5 concurrent tasks
# weight 1.0 â†’ 10 concurrent tasks
```

**How Load Balancing Works (Implicit)**:

The system achieves weighted load distribution **naturally** through the pull model:

1. **Higher weight = More capacity**
   - Analyzer with weight 0.5 has 5 task slots
   - Analyzer with weight 0.2 has 2 task slots

2. **Higher capacity = More frequent pulling**
   - Analyzer with 5 slots completes tasks faster â†’ polls more often
   - Analyzer with 2 slots completes tasks slower â†’ polls less often

3. **Result: Proportional work distribution**
   - Over time, work naturally distributes according to weights
   - No explicit routing logic needed!
   - Self-balancing through pull frequency

**Example**:
```
3 Analyzers: weights [0.2, 0.3, 0.5]
Total work: 1000 tasks

Expected distribution:
- Analyzer-1 (0.2): ~200 tasks (20%)
- Analyzer-2 (0.3): ~300 tasks (30%)
- Analyzer-3 (0.5): ~500 tasks (50%)

Actual distribution matches expected within 1-2%!
```

**Implementation**: `analyzer/analyzer.py` - `Analyzer` class

---

### 4. Analyzer Pool

**Purpose**: Manages multiple analyzers with flexible capacity and optional autoscaling.

**Key Features**:
- Creates and manages N analyzer instances
- Configurable weights per analyzer (or default patterns)
- **Autoscaling** (optional):
  - Monitors distributor queue depth
  - Scales up when queue exceeds threshold
  - Scales down when queue is low
  - Respects min/max size limits
  - Cooldown period prevents oscillation
- Preserves stats from scaled-down analyzers
- Distribution analysis (expected vs actual)

**Autoscaling Behavior**:
```python
analyzer_pool = AnalyzerPool(
    distributor_url="http://localhost:8000",
    num_analyzers=2,              # Start with 2
    enable_autoscaling=True,      # Enable autoscaling
    min_size=2,                   # Never go below 2
    max_size=10,                  # Never exceed 10
    scale_up_threshold=50,        # Scale up if queue > 50
    scale_down_threshold=10,      # Scale down if queue < 10
    scale_up_count=2,             # Add 2 at a time (weight 0.5 each)
    scale_down_count=1            # Remove 1 at a time
)
```

**Scaling Actions**:
- **Scale Up**: Adds high-capacity analyzers (weight 0.5 = 5 concurrent tasks)
- **Scale Down**: Removes excess analyzers, preserves their stats
- **Cooldown**: Waits 30s between scaling actions to stabilize

**Implementation**: `analyzer/analyzer.py` - `AnalyzerPool` class

---

### 5. Distributor

**Purpose**: Central work queue and task distribution service.

**Key Features**:

**API Endpoints**:
- `POST /submit` - Emitters submit logs
- `POST /get_work` - Analyzers request work
- `POST /status` - Analyzers send status updates & heartbeats
- `GET /stats` - Get system statistics
- `GET /metrics` - Get scaling metrics

**Core Components**:

1. **Task Queue** (FIFO deque)
   - Stores pending tasks
   - New tasks appended to back
   - Work requests pull from front
   - Priority requeuing (failed tasks go to front)

2. **In-Progress Map**
   - Tracks tasks currently being processed
   - Maps `task_id` â†’ `Task` object
   - Includes last heartbeat timestamp
   - Used for timeout detection

3. **Background Monitor** (runs every 5 seconds)
   - Checks heartbeat timeouts
   - Requeues timed-out tasks (30s timeout)
   - Monitors for autoscaling triggers

4. **Data Store**
   - Separates task metadata from actual log data
   - Efficient memory usage
   - Fast lookup by task ID

**Failure Resilience**:
- Heartbeat monitoring detects failed analyzers
- Tasks automatically timeout after 30s of no heartbeat
- Failed tasks requeued to front of queue
- Other analyzers pick up the work
- **No data loss** - all logs eventually processed

**Colored Logging**:
- All distributor logs prefixed with `[DISTRIBUTOR]` in cyan
- Different colors for different events:
  - ðŸŸ¢ Green: RECEIVED LOG, TASK COMPLETED
  - ðŸ”µ Blue: ASSIGNED WORK
  - ðŸŸ¡ Yellow: HEARTBEAT
  - ðŸŸ£ Magenta: TASK FAILED

**Implementation**: `distributor/distributor.py`

---

## Running the Demos

### Prerequisites

```bash
# Create virtual environment
python3.14 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Terminal Setup

All demos require the distributor running in a separate terminal:

**Terminal 1 (Distributor)**:
```bash
python run_distributor.py
```

Then run any demo in Terminal 2:

---

### Demo 1: Basic System Demo (`demo_setup.py`)

Demonstrates weighted load distribution with 3 fixed-capacity analyzers (weights 0.2, 0.3, 0.5) and shows that work naturally distributes proportionally (20%, 30%, 50%).

```bash
python demo/demo_setup.py
```

---

### Demo 2: Autoscaling Demo (`autoscaling_demo.py`)

Starts with 2 low-capacity analyzers, applies heavy load to trigger autoscaling (watch for ðŸ”¼ SCALING UP), then reduces load to demonstrate scale-down (ðŸ”½ SCALING DOWN).

```bash
python demo/autoscaling_demo.py
```

---

### Demo 3: Failure Resilience Demo (`failure_demo.py`)

Randomly kills analyzers during operation (ðŸ’€ FAILURE INJECTED) to prove the distributor detects timeouts, requeues failed tasks, and achieves 100% completion with no data loss.

```bash
python demo/failure_demo.py
```

---

## Key Features Summary

### âœ… Pull-Based Architecture
- Analyzers actively request work (no push)
- Natural backpressure handling
- No complex routing logic needed

### âœ… Weighted Load Balancing
- Weight determines concurrent task capacity
- Load automatically distributes proportionally
- Self-balancing through pull frequency

### âœ… Autoscaling
- Monitors queue depth automatically
- Adds high-capacity analyzers when needed
- Removes excess capacity when load decreases
- Configurable thresholds and cooldown

### âœ… Failure Resilience
- Heartbeat-based health monitoring
- Automatic timeout detection (30s)
- Failed tasks requeued automatically
- No data loss despite analyzer failures

### âœ… Comprehensive Logging
- Colored distributor logs for visibility
- Per-component log prefixes (emitter-1, analyzer-2, etc.)
- Event-specific colors (received, assigned, completed, failed)
- Detailed statistics and distribution analysis

### âœ… Accurate Metrics
- Thread-safe statistics tracking
- Stats preserved from scaled-down/killed analyzers
- Graceful shutdown with queue draining
- Perfect alignment: Emitted = Received = Processed

---

## Project Structure

```
.
â”œâ”€â”€ distributor/
â”‚   â”œâ”€â”€ distributor.py      # Core distributor logic
â”‚   â””â”€â”€ models.py           # Data models (LogMessage, Task, etc.)
â”‚
â”œâ”€â”€ analyzer/
â”‚   â”œâ”€â”€ analyzer.py         # Analyzer and AnalyzerPool classes
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ emitter/
â”‚   â”œâ”€â”€ log_emitter.py      # LogEmitter and LogEmitterPool classes
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ demo_setup.py       # Basic system demo
â”‚   â”œâ”€â”€ autoscaling_demo.py # Autoscaling demonstration
â”‚   â””â”€â”€ failure_demo.py     # Failure resilience demo
â”‚
â”œâ”€â”€ run_distributor.py      # Start distributor server
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

---

## Configuration Tips

### For High Throughput
```python
# More emitters
emitter_pool = LogEmitterPool(num_emitters=20)

# More high-weight analyzers
analyzer_pool = AnalyzerPool(
    num_analyzers=10,
    weights=0.5  # All high capacity
)
```

### For Testing Autoscaling
```python
# Aggressive autoscaling
analyzer_pool = AnalyzerPool(
    enable_autoscaling=True,
    scale_up_threshold=20,      # Scale up quickly
    scale_check_interval=3.0,   # Check frequently
    scale_cooldown=10.0,        # Short cooldown
    scale_up_count=3            # Add capacity aggressively
)
```

### For Testing Failure Resilience
```python
# In failure_demo.py, adjust:
failure_rate=0.6  # Kill 60% of checks (more chaos!)
```

---

## Additional Documentation

- **`NEW_FEATURES.md`** - Overview of autoscaling and failure resilience
- **`AUTOSCALING_GUIDE.md`** - Detailed autoscaling configuration and tuning
- **`DISTRIBUTOR_LOGGING.md`** - Guide to distributor log format and colors

---

## Requirements

- Python 3.10+
- FastAPI
- Uvicorn
- Pydantic
- httpx

Install with:
```bash
pip install -r requirements.txt
```

---

## License

MIT
